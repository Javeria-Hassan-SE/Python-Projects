{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a3763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def get_text_order(image_path, font_size, font_type):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to preprocess the image\n",
    "    _, threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Perform morphological operations to enhance text extraction\n",
    "    morphed = cv2.morphologyEx(threshold, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Find contours in the image\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort the contours based on their bounding box coordinates\n",
    "    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0])\n",
    "\n",
    "    # Initialize a list to store the text and its corresponding bounding boxes\n",
    "    text_boxes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Extract the region of interest (ROI) containing the text\n",
    "        roi = gray[y:y + h, x:x + w]\n",
    "\n",
    "        # Convert the ROI to an image object\n",
    "        pil_roi = Image.fromarray(roi)\n",
    "\n",
    "        # Perform OCR using Tesseract to extract the text\n",
    "        text = pytesseract.image_to_string(pil_roi)\n",
    "\n",
    "        # Store the text and its bounding box coordinates\n",
    "        text_boxes.append((text, x, y, w, h))\n",
    "\n",
    "    # Filter text based on font size and type\n",
    "    filtered_text_boxes = [\n",
    "        (text, x, y, w, h) for text, x, y, w, h in text_boxes if get_font_size(image_path, x, y, w, h) == font_size and get_font_type(image_path, x, y, w, h) == font_type\n",
    "    ]\n",
    "\n",
    "    # Sort the filtered text boxes based on their y-coordinate (top to bottom)\n",
    "    sorted_text_boxes = sorted(filtered_text_boxes, key=lambda x: x[2])\n",
    "\n",
    "    # Print the order of the text\n",
    "    for i, (text, _, _, _, _) in enumerate(sorted_text_boxes):\n",
    "        print(f\"User looks at text {i + 1}: {text}\")\n",
    "\n",
    "def get_font_size(image_path, x, y, w, h):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Calculate the average pixel intensity within the bounding box\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    average_intensity = np.mean(roi)\n",
    "\n",
    "    # Determine the font size based on average intensity (adjust these thresholds as needed)\n",
    "    if average_intensity < 100:\n",
    "        font_size = \"Small\"\n",
    "    elif average_intensity < 150:\n",
    "        font_size = \"Medium\"\n",
    "    else:\n",
    "        font_size = \"Large\"\n",
    "\n",
    "    return font_size\n",
    "\n",
    "def get_font_type(image_path, x, y, w, h):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Calculate the average intensity within the bounding box\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    average_intensity = np.mean(roi)\n",
    "\n",
    "    # Determine the font type based on average intensity (adjust these thresholds as needed)\n",
    "    if average_intensity < 100:\n",
    "        font_type = \"Sans-serif\"\n",
    "    elif average_intensity < 150:\n",
    "        font_type = \"Serif\"\n",
    "    else:\n",
    "        font_type = \"Handwriting\"\n",
    "\n",
    "    return font_type\n",
    "\n",
    "# Provide the path to the image\n",
    "image_path = \"text.png\"\n",
    "\n",
    "# Specify the font size and type you want to analyze\n",
    "font_size = \"Medium\"\n",
    "font_type = \"Sans-serif\"\n",
    "\n",
    "# Call the function to get the text order\n",
    "print(get_text_order(image_path, font_size, font_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0782039",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'saliency'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2308\\882408730.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Calculate the saliency map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0msaliency_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_saliency_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# Visualize the saliency map overlaid on the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2308\\882408730.py\u001b[0m in \u001b[0;36mcalculate_saliency_map\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Create a saliency object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msaliency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaliency\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStaticSaliencyFineGrained_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Calculate the saliency map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'saliency'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def calculate_saliency_map(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a saliency object\n",
    "    saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "\n",
    "    # Calculate the saliency map\n",
    "    _, saliency_map = saliency.computeSaliency(gray)\n",
    "\n",
    "    # Normalize the saliency map to have values between 0 and 1\n",
    "    saliency_map = (saliency_map - np.min(saliency_map)) / (np.max(saliency_map) - np.min(saliency_map))\n",
    "\n",
    "    return saliency_map\n",
    "\n",
    "def visualize_saliency_map(image_path, saliency_map):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the saliency map to match the image size\n",
    "    saliency_map = cv2.resize(saliency_map, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Apply a colormap to the saliency map\n",
    "    saliency_map_colored = cm.jet(saliency_map)\n",
    "\n",
    "    # Overlay the saliency map on the image\n",
    "    saliency_overlay = cv2.addWeighted(image, 0.7, saliency_map_colored, 0.3, 0)\n",
    "\n",
    "    # Display the image with the saliency map\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(cv2.cvtColor(saliency_overlay, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Provide the path to the image\n",
    "image_path = \"text.png\"\n",
    "\n",
    "# Calculate the saliency map\n",
    "saliency_map = calculate_saliency_map(image_path)\n",
    "\n",
    "# Visualize the saliency map overlaid on the image\n",
    "visualize_saliency_map(image_path, saliency_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140fe30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
